{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Superstore PySpark Assignment\n", "This notebook answers Questions 9\u201314 from the Module 1 Assignment using PySpark and the Superstore dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install Spark and Java (only needed on Colab)\n", "!apt-get install openjdk-17-jdk-headless -qq > /dev/null\n", "!wget -q https://downloads.apache.org/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n", "!tar xf spark-3.4.1-bin-hadoop3.tgz\n", "!pip install -q findspark\n", "\n", "import os\n", "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n", "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n", "\n", "import findspark\n", "findspark.init()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql import SparkSession\n", "from pyspark.sql.functions import avg, max as spark_max, count, expr\n", "from pyspark.sql.types import DoubleType\n", "\n", "# Initialize Spark\n", "spark = SparkSession.builder.appName(\"SuperstoreAssignment\").getOrCreate()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Upload the Superstore CSV manually\n", "from google.colab import files\n", "uploaded = files.upload()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load CSV into Spark\n", "df = spark.read.csv(\"Superstore.csv\", header=True, inferSchema=True)\n", "\n", "# Cast relevant columns to numeric\n", "df = df.withColumn(\"Sales\", expr(\"try_cast(Sales as double)\"))\n", "df = df.withColumn(\"Profit\", expr(\"try_cast(Profit as double)\"))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Q9: Who is the customer that generated the most sales?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["top_customer = df.groupBy(\"Customer Name\").sum(\"Sales\").orderBy(\"sum(Sales)\", ascending=False)\n", "top_customer.show(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Q10: Highest average sales per transaction for any city"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["avg_sales = df.groupBy(\"City\").agg(avg(\"Sales\").alias(\"avg_sales\")).orderBy(\"avg_sales\", ascending=False)\n", "avg_sales.show(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Q11: Highest total profit for any item"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["profit_by_item = df.groupBy(\"Item\").agg(spark_max(\"Profit\").alias(\"max_profit\")).orderBy(\"max_profit\", ascending=False)\n", "profit_by_item.show(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Q12: Largest number of transactions for any combination of state and customer segment"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["transactions = df.groupBy(\"State\", \"Customer Segment\").agg(count(\"Order ID\").alias(\"transaction_count\")).orderBy(\"transaction_count\", ascending=False)\n", "transactions.show(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Q13: Highest average profit for any city-state combination"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.createOrReplaceTempView(\"superstore\")\n", "result = spark.sql(\"\"\"\n", "SELECT City, State, AVG(Profit) as avg_profit\n", "FROM superstore\n", "GROUP BY City, State\n", "ORDER BY avg_profit DESC\n", "LIMIT 1\n", "\"\"\")\n", "result.show(1)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.12"}}, "nbformat": 4, "nbformat_minor": 2}